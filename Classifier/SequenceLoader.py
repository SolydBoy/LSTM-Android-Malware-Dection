import os
import sys
import random

import numpy as np
from keras.utils.data_utils import Sequence
from keras.utils.np_utils import to_categorical
import pandas as pd

from FeatureExtraction.featureExtraction import featureExtraction
from sklearn.utils import shuffle
from tensorflow.keras.preprocessing.sequence import pad_sequences

import keras

MALWARE_DIR = "malware"
BENING_DIR = "benign"

class SequenceLoarder(Sequence):
    def __init__(self, database_path, path_to_data, batch_size=32, n_classes=2, shuffle=True,
                 padding=False):
        self.list_IDs = os.listdir(path_to_data)
        self.labels = self.find_labels(database_path)
        self.path_to_data = path_to_data
        self.batch_size = batch_size
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.padding = padding
        self.dim = self.find_shape()
        self.indexes = {}
        for i, element in enumerate(self.list_IDs):
            self.indexes[element] = self.labels[i]
        self.on_epoch_end()

    def find_labels(self, database_path):
        malware = os.listdir(f"{database_path}/{MALWARE_DIR}")
        labels = []
        i = 0
        for element in self.list_IDs:
            is_malware = False
            for m in malware:
                if element.split('.')[0] == m.split('.')[0]:
                    labels.append(1)
                    is_malware = True
            if not is_malware:
                labels.append(0)
        return labels

    def find_shape(self):
        return pd.read_csv(f"{self.path_to_data}/{self.list_IDs[0]}").shape

    def on_epoch_end(self):
        if self.shuffle:
            random.shuffle(self.list_IDs)

    def __data_generation(self, list_IDs_temp):

        y = np.empty((self.batch_size), dtype=int)
        # Generate data
        temp_data = []
        for i, ID in enumerate(list_IDs_temp):
            temp_data.append(pd.read_csv(f"{self.path_to_data}/{ID}"))
            y[i] = self.indexes[ID]
        if self.padding:
            X = pad_sequences(temp_data, padding="post")
        return X, y

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.list_IDs[index * self.batch_size:(index + 1) * self.batch_size]
        # Generate data
        X, y = self.__data_generation(indexes)

        return X, y
