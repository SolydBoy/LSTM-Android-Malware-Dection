from typing import Tuple
import numpy as np
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier


class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


class classifier:
    def __init__(self, X_train, y_train, X_test=None, y_test=None):

        if X_test is None or y_test is None:
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_train, y_train,
                                                                                    test_size=0.4,
                                                                                    random_state=0)
        else:
            self.X_train = X_train
            self.y_train = y_train
            self.X_test = X_test
            self.y_test = y_test
        print((self.X_train.shape, self.y_train.shape))
        print((self.X_test.shape, self.y_test.shape))

    def confusion_matrix(self, pred):
        print("Confusion matrix: ")
        print(confusion_matrix(self.y_test, pred))
        return

    def classification_report(self, pred):
        print("Report: ")
        print(classification_report(self.y_test, pred))
        return

    def accuracy_score(self, pred):
        ac = accuracy_score(self.y_test, pred)
        print(f"{bcolors.BOLD}Accuracy{bcolors.ENDC}:", end=' ')
        if ac > 0.80:
            print(f"{bcolors.OKGREEN}{accuracy_score(self.y_test, pred)} {bcolors.ENDC}")
        elif ac > 0.65:
            print(f"{bcolors.WARNING}{accuracy_score(self.y_test, pred)} {bcolors.ENDC}")
        else:
            print(f"{bcolors.FAIL}{accuracy_score(self.y_test, pred)} {bcolors.ENDC}")
        return

    def linear_regression(self) -> Tuple[LinearRegression, int]:
        reg = LinearRegression().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def random_forest(self, n_estimator: int = 100, random_state: int = 2020):
        reg = RandomForestRegressor(n_estimators=n_estimator, random_state=random_state).fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def logistic_regression(self):
        reg = LogisticRegression().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def J48(self):
        reg = tree.DecisionTreeClassifier().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def MLP(self, random_state: int = 1, max_iter: int = 300):
        reg = MLPClassifier(random_state=random_state, max_iter=max_iter).fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def SGD_classifier(self):
        reg = SGDClassifier().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred