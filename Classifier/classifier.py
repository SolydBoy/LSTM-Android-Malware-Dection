import sys
import time
from typing import Tuple

import numpy as np
import tensorflow as tf
from sklearn import tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from Classifier.SequenceLoader import SequenceLoarder


class BColors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


class classifier:
    def __init__(self, X_train=None, y_train=None, X_test=None, y_test=None, name=f'{time.time()}'):
        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test
        self.name = name

    def confusion_matrix(self, pred):
        print("Confusion matrix: ")
        print(confusion_matrix(self.y_test, pred))
        return

    def classification_report(self, pred):
        print("Report: ")
        print(classification_report(self.y_test, pred))
        return

    def accuracy_score(self, pred):
        ac = accuracy_score(self.y_test, pred)
        print(f"{BColors.BOLD}Accuracy{BColors.ENDC}:", end=' ')
        if ac > 0.80:
            print(f"{BColors.OKGREEN}{accuracy_score(self.y_test, pred)} {BColors.ENDC}")
        elif ac > 0.65:
            print(f"{BColors.WARNING}{accuracy_score(self.y_test, pred)} {BColors.ENDC}")
        else:
            print(f"{BColors.FAIL}{accuracy_score(self.y_test, pred)} {BColors.ENDC}")
        return

    def linear_regression(self) -> Tuple[LinearRegression, int]:
        reg = LinearRegression().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def random_forest(self, n_estimator: int = 100, random_state: int = 2020):
        reg = RandomForestRegressor(n_estimators=n_estimator, random_state=random_state).fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def logistic_regression(self):
        reg = LogisticRegression().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def J48(self):
        reg = tree.DecisionTreeClassifier().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def MLP(self, random_state: int = 1, max_iter: int = 300):
        reg = MLPClassifier(random_state=random_state, max_iter=max_iter).fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def SGD_classifier(self):
        reg = SGDClassifier().fit(self.X_train, self.y_train)
        pred = reg.predict(self.X_test)
        binary_pred = np.vectorize(lambda t: 1 if t > 0 else 0)(pred)
        self.confusion_matrix(binary_pred)
        self.classification_report(binary_pred)
        self.accuracy_score(binary_pred)
        return reg, pred

    def LSTM_classifier(self, train_gene, test_gene, epochs=10):

        # Creation of the model
        model = Sequential()

        # Adding layers
        model.add(LSTM(64, return_sequences=True, input_shape=(None, train_gene.dim[-1])))
        model.add(Dense(1, activation="sigmoid"))

        # Compile the model
        opt = tf.keras.optimizers.Adam()
        model.compile(loss="binary_crossentropy", optimizer=opt, metrics=['accuracy'])
        model.summary()

        # Fit
        tensorBoard = TensorBoard(log_dir=f'logs/{self.name}')
        model.fit(train_gene, epochs=epochs, callbacks=[tensorBoard], use_multiprocessing=True,
                  steps_per_epoch=int(len(train_gene.list_IDs) / train_gene.batch_size))

        print("TESTING")
        results = model.evaluate(test_gene, batch_size=test_gene.batch_size)
        model.save("")


if __name__ == '__main__':
    train_gene = SequenceLoarder("C:/Users/Basile/Documents/GitHub/LSTM-Android-Malware-Dection/DataBase/train",
                                 "D:/Train_Typed_1628949090.414119", padding=True, batch_size=10, shuffle=True)
    test_gene = SequenceLoarder("C:/Users/Basile/Documents/GitHub/LSTM-Android-Malware-Dection/DataBase/test",
                                "D:/Test_Typed_1628958476.9498594", padding=True, batch_size=1, shuffle=True)
    classifier = classifier(name="tanh_TYPED_16_30")
    classifier.LSTM_classifier(train_gene, test_gene, 60)
