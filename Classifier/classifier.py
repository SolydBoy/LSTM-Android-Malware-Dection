import tensorflow as tf
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from Classifier.SequenceLoader import SequenceLoarder


def LSTM_classifier(train_gene: SequenceLoarder, test_gene: SequenceLoarder, epochs: int = 10, name: str = ""):
    """
        Train the LSTM model
        ...
        Parameters
        ----------
        train_gene : str
            Generator for the training set.
        test_gene : str
            Generator for the test set.
        epochs : int
            Number of epochs used for the training.
        name : str
            Name of the model used for the save.
    """

    # Creation of the model
    model = Sequential()

    # Adding layers
    model.add(LSTM(64, return_sequences=True, input_shape=(None, train_gene.dim[-1])))
    model.add(Dense(1, activation="sigmoid"))

    # Compile the model
    opt = tf.keras.optimizers.Adam()
    model.compile(loss="binary_crossentropy", optimizer=opt, metrics=['accuracy'])
    model.summary()

    # Fit
    tensor_board = TensorBoard(log_dir=f'logs/{name}')
    model.fit(train_gene, epochs=epochs, callbacks=[tensor_board], use_multiprocessing=True,
              steps_per_epoch=int(len(train_gene.list_IDs) / train_gene.batch_size))

    print("TESTING")
    model.evaluate(test_gene, batch_size=test_gene.batch_size)
    model.save(name)
